{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS395 - Assignment 6\n",
    "### Multi-Step LSTMs\n",
    "\n",
    "Date: March 3, 2019  \n",
    "By: Joshua Eli Swick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "# multi-step data preparation\n",
    "from numpy import array \n",
    "\n",
    "# univariate multi-step vector-output stacked lstm example \n",
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM \n",
    "from keras.layers import Dense \n",
    "\n",
    "# univariate multi-step encoder-decoder lstm example\n",
    "from keras.layers import RepeatVector \n",
    "from keras.layers import TimeDistributed \n",
    "\n",
    "# bidirectional lstm\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "# multivariate multi-step data preparation\n",
    "from numpy import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples \n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list() \n",
    "    for i in range(len(sequence)): \n",
    "        # find the end of this pattern \n",
    "        end_ix = i + n_steps_in \n",
    "        out_end_ix = end_ix + n_steps_out \n",
    "        # check if we are beyond the sequence \n",
    "        if out_end_ix > len(sequence): \n",
    "              break \n",
    "        # gather input and output parts of the pattern \n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix] \n",
    "        X.append(seq_x) \n",
    "        y.append(seq_y) \n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. \n",
    "Run given code and show results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] [40 50]\n",
      "[20 30 40] [50 60]\n",
      "[30 40 50] [60 70]\n",
      "[40 50 60] [70 80]\n",
      "[50 60 70] [80 90]\n"
     ]
    }
   ],
   "source": [
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Output Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. \n",
    "Run the given code 3 times. Show input once and all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Output LSTM, run 1: [[102.79567  116.121346]]\n",
      "Vector Output LSTM, run 2: [[101.06105 115.52495]]\n",
      "Vector Output LSTM, run 3: [[100.88695 129.13826]]\n",
      "\n",
      "x_input: \n",
      "[[[70]\n",
      "  [80]\n",
      "  [90]]]\n"
     ]
    }
   ],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features] \n",
    "n_features = 1 \n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "for run in range(3):\n",
    "    # define model \n",
    "    model = Sequential() \n",
    "    model.add(LSTM(100, activation='relu', return_sequences=True, \n",
    "                   input_shape=(n_steps_in, n_features))) \n",
    "    model.add(LSTM(100, activation='relu')) \n",
    "    model.add(Dense(n_steps_out)) \n",
    "    model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "    # fit model \n",
    "    model.fit(X, y, epochs=50, verbose=0) \n",
    "\n",
    "    # demonstrate prediction \n",
    "    x_input = array([70, 80, 90]) \n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features)) \n",
    "    yhat = model.predict(x_input, verbose=0) \n",
    "\n",
    "    print(f\"Vector Output LSTM, run {run+1}: {yhat}\") \n",
    "\n",
    "print(f\"\\nx_input: \\n{x_input}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. \n",
    "Change the activation function from 'relu' to 2 other activation functions. Run each function 3 times. Show all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Output LSTM, selu activation function, run 1: [[105.630646 118.06458 ]]\n",
      "Vector Output LSTM, selu activation function, run 2: [[106.83967 121.45907]]\n",
      "Vector Output LSTM, selu activation function, run 3: [[107.29903 123.11093]]\n"
     ]
    }
   ],
   "source": [
    "for run in range(3):\n",
    "    # define model \n",
    "    model = Sequential() \n",
    "    model.add(LSTM(100, activation='selu', return_sequences=True,  # selu instead of relu\n",
    "                   input_shape=(n_steps_in, n_features))) \n",
    "    model.add(LSTM(100, activation='selu')) \n",
    "    model.add(Dense(n_steps_out)) \n",
    "    model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "    # fit model \n",
    "    model.fit(X, y, epochs=50, verbose=0) \n",
    "\n",
    "    # demonstrate prediction \n",
    "    x_input = array([70, 80, 90]) \n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features)) \n",
    "    yhat = model.predict(x_input, verbose=0) \n",
    "\n",
    "    print(f\"Vector Output LSTM, selu activation function, run {run+1}: {yhat}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Output LSTM, elu activation function, run 1: [[109.80136 122.74441]]\n",
      "Vector Output LSTM, elu activation function, run 2: [[111.408516 124.25589 ]]\n",
      "Vector Output LSTM, elu activation function, run 3: [[104.200806 120.476204]]\n"
     ]
    }
   ],
   "source": [
    "for run in range(3):\n",
    "    # define model \n",
    "    model = Sequential() \n",
    "    model.add(LSTM(100, activation='elu', return_sequences=True,  # elu instead of relu\n",
    "                   input_shape=(n_steps_in, n_features))) \n",
    "    model.add(LSTM(100, activation='elu')) \n",
    "    model.add(Dense(n_steps_out)) \n",
    "    model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "    # fit model \n",
    "    model.fit(X, y, epochs=50, verbose=0) \n",
    "\n",
    "    # demonstrate prediction \n",
    "    x_input = array([70, 80, 90]) \n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features)) \n",
    "    yhat = model.predict(x_input, verbose=0) \n",
    "\n",
    "    print(f\"Vector Output LSTM, elu activation function, run {run+1}: {yhat}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-Decoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\n",
    "Run the given code 3 times. Show input once and all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder-Decoder LSTM, run 1: \n",
      "[[[106.222305]\n",
      "  [118.724464]]]\n",
      "Encoder-Decoder LSTM, run 2: \n",
      "[[[107.75766]\n",
      "  [125.63242]]]\n",
      "Encoder-Decoder LSTM, run 3: \n",
      "[[[104.9773 ]\n",
      "  [117.74535]]]\n",
      "\n",
      "x_input: \n",
      "[[[70]\n",
      "  [80]\n",
      "  [90]]]\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "y = y.reshape((y.shape[0], y.shape[1], n_features))\n",
    "\n",
    "for run in range(3):\n",
    "    # define model \n",
    "    model = Sequential() \n",
    "    model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features))) \n",
    "    model.add(RepeatVector(n_steps_out)) \n",
    "    model.add(LSTM(100, activation='relu', return_sequences=True)) \n",
    "    model.add(TimeDistributed(Dense(1))) \n",
    "    model.compile(optimizer='adam', loss='mse') \n",
    "    # fit model \n",
    "    model.fit(X, y, epochs=100, verbose=0) \n",
    "    # demonstrate prediction \n",
    "    x_input = array([70, 80, 90]) \n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features)) \n",
    "    yhat = model.predict(x_input, verbose=0) \n",
    "    print(f\"Encoder-Decoder LSTM, run {run+1}: \\n{yhat}\") \n",
    "\n",
    "print(f\"\\nx_input: \\n{x_input}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\n",
    "Change the activation function from 'relu' to 2 other activation functions. Run each function 3 times. Show all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder-Decoder LSTM, elu activation function, run 1: \n",
      "[[[ 97.71329 ]\n",
      "  [111.263145]]]\n",
      "Encoder-Decoder LSTM, elu activation function, run 2: \n",
      "[[[ 98.90968]\n",
      "  [111.2552 ]]]\n",
      "Encoder-Decoder LSTM, elu activation function, run 3: \n",
      "[[[104.62835]\n",
      "  [113.66432]]]\n"
     ]
    }
   ],
   "source": [
    "for run in range(3):\n",
    "    # define model \n",
    "    model = Sequential() \n",
    "    model.add(LSTM(100, activation='elu', input_shape=(n_steps_in, n_features)))  # elu activation function \n",
    "    model.add(RepeatVector(n_steps_out)) \n",
    "    model.add(LSTM(100, activation='elu', return_sequences=True)) \n",
    "    model.add(TimeDistributed(Dense(1))) \n",
    "    model.compile(optimizer='adam', loss='mse') \n",
    "    # fit model \n",
    "    model.fit(X, y, epochs=100, verbose=0) \n",
    "    # demonstrate prediction \n",
    "    x_input = array([70, 80, 90]) \n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features)) \n",
    "    yhat = model.predict(x_input, verbose=0) \n",
    "    print(f\"Encoder-Decoder LSTM, elu activation function, run {run+1}: \\n{yhat}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder-Decoder LSTM, selu activation function, run 1: \n",
      "[[[102.055504]\n",
      "  [112.62822 ]]]\n",
      "Encoder-Decoder LSTM, selu activation function, run 2: \n",
      "[[[ 98.53076 ]\n",
      "  [113.305176]]]\n",
      "Encoder-Decoder LSTM, selu activation function, run 3: \n",
      "[[[102.606995]\n",
      "  [116.574745]]]\n"
     ]
    }
   ],
   "source": [
    "for run in range(3):\n",
    "    # define model \n",
    "    model = Sequential() \n",
    "    model.add(LSTM(100, activation='selu', input_shape=(n_steps_in, n_features)))  # selu activation function \n",
    "    model.add(RepeatVector(n_steps_out)) \n",
    "    model.add(LSTM(100, activation='selu', return_sequences=True)) \n",
    "    model.add(TimeDistributed(Dense(1))) \n",
    "    model.compile(optimizer='adam', loss='mse') \n",
    "    # fit model \n",
    "    model.fit(X, y, epochs=100, verbose=0) \n",
    "    # demonstrate prediction \n",
    "    x_input = array([70, 80, 90]) \n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features)) \n",
    "    yhat = model.predict(x_input, verbose=0) \n",
    "    print(f\"Encoder-Decoder LSTM, selu activation function, run {run+1}: \\n{yhat}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\n",
    "Change the activation function back to 'relu'. Change this model to two of the other univariate LSTM models (i.e. Stacked, Bidirectional, CNN, or Conv LSTM) to create an Encoder-Decoder Model <x> LSTM, where <x> is the other univariate function model. Run 3 times, show all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder-Decoder Bidirectional LSTM, relu activation function, run 1: \n",
      "[[[101.18164 ]\n",
      "  [113.611176]]]\n",
      "Encoder-Decoder Bidirectional LSTM, relu activation function, run 2: \n",
      "[[[102.268974]\n",
      "  [117.79098 ]]]\n",
      "Encoder-Decoder Bidirectional LSTM, relu activation function, run 3: \n",
      "[[[102.80594]\n",
      "  [116.99763]]]\n"
     ]
    }
   ],
   "source": [
    "for run in range(3):\n",
    "    # define model \n",
    "    model = Sequential() \n",
    "    model.add(Bidirectional(LSTM(100, activation='relu'), input_shape=(n_steps_in, n_features)))\n",
    "    model.add(RepeatVector(n_steps_out)) \n",
    "    model.add(LSTM(100, activation='relu', return_sequences=True)) \n",
    "    model.add(TimeDistributed(Dense(1))) \n",
    "    model.compile(optimizer='adam', loss='mse') \n",
    "    # fit model \n",
    "    model.fit(X, y, epochs=100, verbose=0) \n",
    "    # demonstrate prediction \n",
    "    x_input = array([70, 80, 90]) \n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features)) \n",
    "    yhat = model.predict(x_input, verbose=0) \n",
    "    print(f\"Encoder-Decoder Bidirectional LSTM, relu activation function, run {run+1}: \\n{yhat}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder-Decoder Bidirectional LSTM, relu activation function, run 1: \n",
      "[[[105.266975]\n",
      "  [121.959465]]]\n",
      "Encoder-Decoder Bidirectional LSTM, relu activation function, run 2: \n",
      "[[[103.31849 ]\n",
      "  [122.195526]]]\n",
      "Encoder-Decoder Bidirectional LSTM, relu activation function, run 3: \n",
      "[[[100.53522 ]\n",
      "  [113.311424]]]\n"
     ]
    }
   ],
   "source": [
    "for run in range(3):\n",
    "    # define model \n",
    "    model = Sequential() \n",
    "    model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "    model.add(LSTM(100, activation='relu'))\n",
    "    model.add(RepeatVector(n_steps_out)) \n",
    "    model.add(LSTM(100, activation='relu', return_sequences=True)) \n",
    "    model.add(TimeDistributed(Dense(1))) \n",
    "    model.compile(optimizer='adam', loss='mse') \n",
    "    # fit model \n",
    "    model.fit(X, y, epochs=100, verbose=0) \n",
    "    # demonstrate prediction \n",
    "    x_input = array([70, 80, 90]) \n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features)) \n",
    "    yhat = model.predict(x_input, verbose=0) \n",
    "    print(f\"Encoder-Decoder Bidirectional LSTM, relu activation function, run {run+1}: \\n{yhat}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Input Multi-Step Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. \n",
    "Run the given code, show all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 3) (5, 2, 3)\n",
      "[[10 15 25]\n",
      " [20 25 45]\n",
      " [30 35 65]] [[ 40  45  85]\n",
      " [ 50  55 105]]\n",
      "[[20 25 45]\n",
      " [30 35 65]\n",
      " [40 45 85]] [[ 50  55 105]\n",
      " [ 60  65 125]]\n",
      "[[ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]] [[ 60  65 125]\n",
      " [ 70  75 145]]\n",
      "[[ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]] [[ 70  75 145]\n",
      " [ 80  85 165]]\n",
      "[[ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]] [[ 80  85 165]\n",
      " [ 90  95 185]]\n"
     ]
    }
   ],
   "source": [
    "# define input sequence \n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90]) \n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95]) \n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))]) \n",
    "\n",
    "# convert to [rows, columns] structure \n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1)) \n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1)) \n",
    "out_seq = out_seq.reshape((len(out_seq), 1)) \n",
    "\n",
    "# horizontally stack columns \n",
    "dataset = hstack((in_seq1, in_seq2, out_seq)) \n",
    "\n",
    "# choose a number of time steps \n",
    "n_steps_in, n_steps_out = 3, 2 \n",
    "\n",
    "# covert into input/output \n",
    "X, y = split_sequence(dataset, n_steps_in, n_steps_out) \n",
    "print(X.shape, y.shape) \n",
    "\n",
    "# summarize the data \n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.\n",
    "Run the given code 3 times. Show input once and all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate multi-step stacked LSTM, run 1: [[187.53465 209.63057]]\n",
      "Multivariate multi-step stacked LSTM, run 2: [[187.53015 208.98615]]\n",
      "Multivariate multi-step stacked LSTM, run 3: [[186.30579 207.78137]]\n",
      "\n",
      "Input: \n",
      "[[[70 75]\n",
      "  [80 85]\n",
      "  [90 95]]]\n"
     ]
    }
   ],
   "source": [
    "# multivariate multi-step stacked lstm example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "for run in range(3):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, activation='relu', return_sequences=True,\n",
    "    input_shape=(n_steps_in, n_features)))\n",
    "    model.add(LSTM(100, activation='relu'))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # fit model\n",
    "    model.fit(X, y, epochs=200, verbose=0)\n",
    "    # demonstrate prediction\n",
    "    x_input = array([[70, 75], [80, 85], [90, 95]])\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    print(f\"Multivariate multi-step stacked LSTM, run {run+1}: {yhat}\")\n",
    "    \n",
    "print(f\"\\nInput: \\n{x_input}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.\n",
    "Change the activation function from 'relu' to 2 other activation functions. Run each function 3 times. Show all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate multi-step stacked LSTM, elu activation function, run 1: [[187.28606 209.56604]]\n",
      "Multivariate multi-step stacked LSTM, elu activation function, run 2: [[185.96056 208.4713 ]]\n",
      "Multivariate multi-step stacked LSTM, elu activation function, run 3: [[186.3392  208.25137]]\n"
     ]
    }
   ],
   "source": [
    "for run in range(3):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, activation='elu', return_sequences=True,\n",
    "    input_shape=(n_steps_in, n_features)))\n",
    "    model.add(LSTM(100, activation='elu'))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # fit model\n",
    "    model.fit(X, y, epochs=200, verbose=0)\n",
    "    # demonstrate prediction\n",
    "    x_input = array([[70, 75], [80, 85], [90, 95]])\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    print(f\"Multivariate multi-step stacked LSTM, elu activation function, run {run+1}: {yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate multi-step stacked LSTM, selu activation function, run 1: [[184.79706 206.01259]]\n",
      "Multivariate multi-step stacked LSTM, selu activation function, run 2: [[184.9093  206.20804]]\n",
      "Multivariate multi-step stacked LSTM, selu activation function, run 3: [[186.09892 206.44264]]\n"
     ]
    }
   ],
   "source": [
    "for run in range(3):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, activation='selu', return_sequences=True,\n",
    "    input_shape=(n_steps_in, n_features)))\n",
    "    model.add(LSTM(100, activation='selu'))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # fit model\n",
    "    model.fit(X, y, epochs=200, verbose=0)\n",
    "    # demonstrate prediction\n",
    "    x_input = array([[70, 75], [80, 85], [90, 95]])\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    print(f\"Multivariate multi-step stacked LSTM, selu activation function, run {run+1}: {yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Parallel Input and Multi-Step Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.\n",
    "Run given code and show all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3) (1, 2, 3)\n",
      "[[10 15 25]\n",
      " [20 25 45]\n",
      " [30 35 65]] [[ 40  45  85]\n",
      " [ 50  55 105]]\n"
     ]
    }
   ],
   "source": [
    "# multivariate multi-step data preparation\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        return array(X), array(y)\n",
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "print(X.shape, y.shape)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.\n",
    "Run the given code 3 times. Show input once and all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate multi-step encoder-decoder LSTM, run 1: \n",
      "[[[ 91.814384  97.35714  189.79308 ]\n",
      "  [102.57893  108.27749  212.25337 ]]]\n",
      "Multivariate multi-step encoder-decoder LSTM, run 2: \n",
      "[[[ 90.856224  96.021126 187.33286 ]\n",
      "  [101.30607  106.89735  209.14952 ]]]\n",
      "Multivariate multi-step encoder-decoder LSTM, run 3: \n",
      "[[[ 91.2538   97.36612 188.6374 ]\n",
      "  [103.67517 108.71683 212.24504]]]\n",
      "\n",
      "Input: \n",
      "[[[ 60  65 125]\n",
      "  [ 70  75 145]\n",
      "  [ 80  85 165]]]\n"
     ]
    }
   ],
   "source": [
    "# multivariate multi-step encoder-decoder lstm example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "for run in range(3):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "    model.add(RepeatVector(n_steps_out))\n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # fit model\n",
    "    model.fit(X, y, epochs=300, verbose=0)\n",
    "    # demonstrate prediction\n",
    "    x_input = array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    print(f\"Multivariate multi-step encoder-decoder LSTM, run {run+1}: \\n{yhat}\")\n",
    "\n",
    "print(f\"\\nInput: \\n{x_input}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.\n",
    "Change the activation function from 'relu' to 2 other activation functions. Run each function 3 times. Show all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate multi-step encoder-decoder LSTM, selu activation function, run 1: \n",
      "[[[ 90.20457   95.72145  186.1131  ]\n",
      "  [101.35735  106.545975 208.0106  ]]]\n",
      "Multivariate multi-step encoder-decoder LSTM, selu activation function, run 2: \n",
      "[[[ 90.3685   95.83061 186.33356]\n",
      "  [101.23498 106.79179 208.53351]]]\n",
      "Multivariate multi-step encoder-decoder LSTM, selu activation function, run 3: \n",
      "[[[ 90.61505  96.22584 186.97276]\n",
      "  [101.72075 107.37853 209.07985]]]\n"
     ]
    }
   ],
   "source": [
    "for run in range(3):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='selu', input_shape=(n_steps_in, n_features)))\n",
    "    model.add(RepeatVector(n_steps_out))\n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # fit model\n",
    "    model.fit(X, y, epochs=300, verbose=0)\n",
    "    # demonstrate prediction\n",
    "    x_input = array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    print(f\"Multivariate multi-step encoder-decoder LSTM, selu activation function, run {run+1}: \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate multi-step encoder-decoder LSTM, elu activation function, run 1: \n",
      "[[[ 90.93138  95.72269 185.8148 ]\n",
      "  [101.75057 106.31448 207.9682 ]]]\n",
      "Multivariate multi-step encoder-decoder LSTM, elu activation function, run 2: \n",
      "[[[ 90.77438   95.68702  186.27686 ]\n",
      "  [101.699715 106.48441  207.80688 ]]]\n",
      "Multivariate multi-step encoder-decoder LSTM, elu activation function, run 3: \n",
      "[[[ 90.35345   95.95481  186.48857 ]\n",
      "  [101.557785 107.302605 208.80862 ]]]\n"
     ]
    }
   ],
   "source": [
    "for run in range(3):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='selu', input_shape=(n_steps_in, n_features)))\n",
    "    model.add(RepeatVector(n_steps_out))\n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # fit model\n",
    "    model.fit(X, y, epochs=300, verbose=0)\n",
    "    # demonstrate prediction\n",
    "    x_input = array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    print(f\"Multivariate multi-step encoder-decoder LSTM, elu activation function, run {run+1}: \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.\n",
    "Provide a single table that illustrates the different LSTM models, the activation functions used, and the average of the 3 results (predictions) to 3 decimal places. What are the general findings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LSTM Model                              | Activation Function | Avg. of 3 Results | General Findings |  \n",
    "| --------------------------------------- | ------------------- | ----------------- | ---------------- |\n",
    "| Vector Output                           | Relu                | [101.581 120.261] | 4th              |\n",
    "| Vector Output                           | Selu                | [106.590 120.878] | 7th              |\n",
    "| Vector Output                           | Elu                 | [108.470 122.492] | 8th              |\n",
    "| Encoder-Decoder                         | Relu                | [106.319 120.700] | 6th              |\n",
    "| Encoder-Decoder                         | Elu                 | [100.417 122.061] | 5th              |\n",
    "| Encoder-Decoder                         | Selu                | [101.067 114.169] | 1st              |\n",
    "| Bidirectional                           | Relu                | [102.086 116.133] | 2nd              |\n",
    "| Stacked                                 | Relu                | [103.040 119.155] | 3rd              |\n",
    "|                                                                                                      |  \n",
    "| Multivariate Multi-Step Stacked         | Relu                | [187.124 208.799] | 3rd              |\n",
    "| Multivariate Multi-Step Stacked         | Elu                 | [186.529 208.763] | 2nd              |\n",
    "| Multivariate Multi-Step Stacked         | Selu                | [185.268 206.221] | 1st              |\n",
    "|                                                                                                      |  \n",
    "| Multivariate Multi-Step Encoder-Decoder | Relu                | [090.873 096.239 187.261] | 3rd              |\n",
    "| -                                       | -                   | [101.814 107.101 209.545] | -                |\n",
    "| Multivariate Multi-Step Encoder-Decoder | Elu                 | [090.396 095.926 186.473] | 2nd              |\n",
    "| -                                       | -                   | [101.438 106.906 208.542] | -                |\n",
    "| Multivariate Multi-Step Encoder-Decoder | Selu                | [090.686 095.788 186.194] | 1st              |\n",
    "| -                                       | -                   | [101.670 106.700 208.195] | -                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the results for each LSTM model were quite accurate. The Selu Activation Function seemed to produce the most accurate predictions, while Relu was the least accurate for Multivariate Multi-Step models and Elu was the least accurate Activation Function for the Univariate models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
